# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sEQyrCIGHE_y4aTkZ1mAKNGQcxxjmQRb
"""

from google.colab import drive
drive.mount('/content/drive')

!cp "/content/drive/Beastie_Boys_Sabotage.mp3" "/content/"
!cp "/content/drive/Jamie_xx_You_ve_Got_The_Love.mp3" "/content/"
!cp "/content/drive/M83_Midnight_City.mp3" "/content/"
!cp "/content/drive/Royksoop_Happy_up_here.mp3" "/content/"
!cp "/content/drive/Tame_Impala_Let_It_Happen.mp3" "/content/"

!pip install numpy librosa matplotlib opencv-python pandas tqdm soundfile pydub

!pip install numpy librosa matplotlib opencv-python pandas tqdm soundfile pydub scipy

import os
import random
import numpy as np
import librosa
import librosa.display
import matplotlib.pyplot as plt
import pandas as pd
from tqdm.auto import tqdm
import cv2
import glob
from typing import List, Tuple, Optional, Dict, Any, Type
import soundfile as sf
from pydub import AudioSegment
from pydub.effects import speedup
import shutil
from abc import ABC, abstractmethod
from scipy.stats import wasserstein_distance

class SongFinder(ABC):
    """Абстрактный базовый класс для поиска песен"""

    def __init__(self, songs_path: str):
        self.songs_path = songs_path
        self.songs_db = self._build_songs_database()

    @abstractmethod
    def _build_songs_database(self) -> Dict[str, Any]:
        pass

    @abstractmethod
    def find_song(self, audio_segment: np.ndarray, sr: int) -> Dict[str, Any]:
        pass

class SimpleSongFinder(SongFinder):
    """Улучшенный алгоритм поиска песен по спектрограммам"""

    def __init__(self, songs_path: str, output_dir: str = "processed_segments", debug: bool = False):
        self.output_dir = output_dir
        self.debug = debug
        super().__init__(songs_path)
        os.makedirs(output_dir, exist_ok=True)

    def _build_songs_database(self) -> Dict[str, Any]:
        db = {}
        print("Building songs database...")

        for song_file in tqdm(glob.glob(os.path.join(self.songs_path, "*.mp3"))):
            song_name = os.path.splitext(os.path.basename(song_file))[0]
            features = self._extract_song_features(song_file)
            if features and len(features) > 0:
                db[song_name] = features
                if self.debug:
                    print(f"Processed {song_name} - got {len(features)} segments")
            else:
                print(f"Warning: no features extracted for {song_name}")

        return db

    def _extract_song_features(self, song_file: str, segment_duration: int = 3) -> List[np.ndarray]:
        temp_dir = os.path.join(self.output_dir, "temp")
        os.makedirs(temp_dir, exist_ok=True)

        try:
            y, sr = librosa.load(song_file, sr=None)
            if len(y) < sr * segment_duration:
                return []

            samples_per_segment = sr * segment_duration
            num_segments = len(y) // samples_per_segment
            spots_list = []

            for i in range(num_segments):
                segment = y[i*samples_per_segment : (i+1)*samples_per_segment]
                spec_path = os.path.join(temp_dir, f"spec_{i}.png")

                # Создаем улучшенную спектрограмму
                D = librosa.stft(segment, n_fft=2048, hop_length=512, win_length=1024)
                S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)

                plt.figure(figsize=(10, 4))
                librosa.display.specshow(S_db, sr=sr, x_axis='time', y_axis='log', cmap='gray_r')
                plt.axis('off')
                plt.savefig(spec_path, bbox_inches='tight', pad_inches=0, dpi=100)
                plt.close()

                # Находим точки улучшенным методом
                spots = self._find_bright_spots(spec_path)
                if len(spots) >= 5:  # Только если найдено достаточно точек
                    spots_list.append(spots)

                    if self.debug and random.random() < 0.2:
                        self._debug_spectrogram(segment, sr, spots)

            return spots_list
        except Exception as e:
            print(f"Error processing {song_file}: {str(e)}")
            return []
        finally:
            shutil.rmtree(temp_dir, ignore_errors=True)

    def _find_bright_spots(self, image_path: str) -> np.ndarray:
        try:
            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
            if image is None:
                return np.array([])

            # Адаптивный порог с морфологическими операциями
            thresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                         cv2.THRESH_BINARY, 11, 2)
            kernel = np.ones((3,3), np.uint8)
            thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)

            # Поиск контуров
            contours, _ = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
            spots = []

            for cnt in contours:
                if cv2.contourArea(cnt) > 2:
                    M = cv2.moments(cnt)
                    if M["m00"] > 0:
                        cX = int(M["m10"] / M["m00"])
                        cY = int(M["m01"] / M["m00"])
                        spots.append((cX, cY))

            return np.array(spots)
        except Exception as e:
            print(f"Error finding spots in {image_path}: {str(e)}")
            return np.array([])

    def _debug_spectrogram(self, audio_data: np.ndarray, sr: int, spots: np.ndarray = None):
        """Визуализация для отладки"""
        D = librosa.stft(audio_data, n_fft=2048, hop_length=512)
        S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)

        plt.figure(figsize=(12, 6))
        plt.subplot(1, 2, 1)
        librosa.display.specshow(S_db, sr=sr, x_axis='time', y_axis='log', cmap='gray_r')
        plt.colorbar(format='%+2.0f dB')
        plt.title('Spectrogram')

        if spots is not None:
            plt.subplot(1, 2, 2)
            plt.scatter(spots[:, 0], spots[:, 1], c='red', s=5)
            plt.gca().invert_yaxis()
            plt.title('Detected Spots')
            plt.xlabel('Time (px)')
            plt.ylabel('Frequency (px)')

        plt.tight_layout()
        plt.show()

    def _improved_distance(self, features1: np.ndarray, features2: np.ndarray) -> float:
        """Улучшенная метрика сравнения с нормализацией"""
        if len(features1) < 5 or len(features2) < 5:
            return float('inf')

        # Нормализация координат
        def normalize(f):
            f = f.astype(np.float32)
            f[:, 0] /= 1000  # Частота
            f[:, 1] /= 100    # Время
            return f

        f1 = normalize(features1)
        f2 = normalize(features2)

        # Используем Earth Mover's Distance
        min_len = min(len(f1), len(f2), 50)
        try:
            x_dist = wasserstein_distance(f1[:min_len, 0], f2[:min_len, 0])
            y_dist = wasserstein_distance(f1[:min_len, 1], f2[:min_len, 1])
            return (x_dist + y_dist) / 2
        except:
            return np.linalg.norm(f1[:min_len] - f2[:min_len])

    def find_song(self, audio_segment: np.ndarray, sr: int) -> Dict[str, Any]:
        temp_dir = os.path.join(self.output_dir, "temp_query")
        os.makedirs(temp_dir, exist_ok=True)

        try:
            # Сохраняем сегмент для анализа
            segment_path = os.path.join(temp_dir, "segment.wav")
            sf.write(segment_path, audio_segment, sr)

            # Извлекаем особенности
            query_features = self._extract_song_features(segment_path, segment_duration=3)

            if not query_features or len(query_features[0]) < 5:
                return {
                    "song_name": None,
                    "distance": float('inf'),
                    "status": "failed",
                    "reason": "Not enough features"
                }

            if self.debug:
                print(f"Query features: {len(query_features[0])} points")
                self._debug_spectrogram(audio_segment, sr, query_features[0])

            # Поиск в базе данных
            best_match = None
            min_distance = float('inf')

            for song_name, song_features in self.songs_db.items():
                for ref_features in song_features:
                    distance = self._improved_distance(query_features[0], ref_features)

                    if self.debug:
                        print(f"Distance to {song_name}: {distance:.2f}")

                    if distance < min_distance:
                        min_distance = distance
                        best_match = song_name

            return {
                "song_name": best_match,
                "distance": min_distance,
                "status": "success" if best_match else "failed",
                "reason": None if best_match else "No match found"
            }
        finally:
            shutil.rmtree(temp_dir, ignore_errors=True)

class MetricsAlongLibrary:
    """Класс для оценки точности алгоритма"""

    def __init__(self, songs_path: str, song_finder_class: Type[SongFinder], **kwargs):
        self.songs_path = songs_path
        self.finder_class = song_finder_class
        self.finder_kwargs = kwargs

    def calculate_accuracy(self, test_samples: int = 10, segment_duration: float = 3.0) -> float:
        finder = self.finder_class(self.songs_path, **self.finder_kwargs)
        song_files = glob.glob(os.path.join(self.songs_path, "*.mp3"))

        if not song_files:
            raise ValueError("No songs found in the specified directory")

        correct = 0
        total = 0

        # Тестируем на каждой песне
        for song_file in tqdm(song_files, desc="Testing songs"):
            song_name = os.path.splitext(os.path.basename(song_file))[0]
            y, sr = librosa.load(song_file, sr=None)

            if len(y) < sr * segment_duration:
                continue

            # Создаем тестовые сегменты
            for _ in range(test_samples):
                start = random.randint(0, len(y) - int(segment_duration * sr))
                segment = y[start : start + int(segment_duration * sr)]

                result = finder.find_song(segment, sr)

                if result["status"] == "success" and result["song_name"] == song_name:
                    correct += 1
                total += 1

        return correct / max(1, total)  # Избегаем деления на 0

# Пример использования
if __name__ == "__main__":
    SONGS_PATH = "/content"  # Укажите путь к песням

    if not os.path.exists(SONGS_PATH):
        os.makedirs(SONGS_PATH)
        print(f"Please upload MP3 files to {SONGS_PATH}")
    else:
        # Проверяем доступные песни
        print("Available songs:")
        for song in glob.glob(os.path.join(SONGS_PATH, "*.mp3")):
            y, sr = librosa.load(song, sr=None)
            print(f"- {os.path.basename(song)} ({len(y)/sr:.1f} sec, {sr} Hz)")

        # Тестируем с визуализацией
        print("\nTesting with visualization...")
        test_finder = SimpleSongFinder(SONGS_PATH, debug=True)

        # Тестируем на случайной песне
        song_file = random.choice(glob.glob(os.path.join(SONGS_PATH, "*.mp3")))
        y, sr = librosa.load(song_file, sr=None)
        segment = y[:int(3 * sr)]  # Берем первые 3 секунды

        result = test_finder.find_song(segment, sr)
        print(f"\nTest result: {result}")

        # Полная оценка точности
        print("\nCalculating full accuracy...")
        metrics = MetricsAlongLibrary(
            SONGS_PATH,
            SimpleSongFinder,
            output_dir="finder_output",
            debug=False
        )

        accuracy = metrics.calculate_accuracy(test_samples=5, segment_duration=3.0)
        print(f"\nFinal Accuracy: {accuracy:.1%}")